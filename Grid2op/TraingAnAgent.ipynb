{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Step [0] -- Random [0.99]\nSurvived [6] steps\nTotal reward [6465.137939453125]\n",
      "Survived [1] steps\nTotal reward [1081.458984375]\nSurvived [2] steps\nTotal reward [2207.4503173828125]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps\nTotal reward [2188.367431640625]\n",
      "Survived [1] steps\nTotal reward [1093.696533203125]\nSurvived [1] steps\nTotal reward [1072.546630859375]\n",
      "Survived [2] steps\nTotal reward [2139.740234375]\nSurvived [1] steps\nTotal reward [1113.323974609375]\n",
      "Survived [1] steps\nTotal reward [1125.119140625]\n",
      "Survived [1] steps\nTotal reward [1103.541748046875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [4] steps\nTotal reward [4359.255615234375]\nSurvived [2] steps\nTotal reward [2243.257568359375]\n",
      "Survived [1] steps\nTotal reward [1087.0404052734375]\n",
      "Survived [5] steps\nTotal reward [5430.3817138671875]\nSurvived [1] steps\nTotal reward [1107.914306640625]\n",
      "Survived [4] steps\nTotal reward [4346.902587890625]\nSurvived [1] steps\nTotal reward [1109.7510986328125]\n",
      "Survived [3] steps\nTotal reward [3242.305908203125]\nSurvived [2] steps\nTotal reward [2236.9697265625]\n",
      "Survived [2] steps\nTotal reward [2158.541015625]\n",
      "Survived [4] steps\nTotal reward [4466.66650390625]\n",
      "Survived [2] steps\nTotal reward [2172.779052734375]\n",
      "Survived [2] steps\nTotal reward [2205.404296875]\nSurvived [2] steps",
      "\nTotal reward [2165.2969970703125]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps",
      "\nTotal reward [2138.353515625]\n",
      "Survived [8] steps\nTotal reward [8951.8427734375]\nSurvived [3] steps",
      "\nTotal reward [3346.9488525390625]\nSurvived [2] steps\nTotal reward [2162.714111328125]\n",
      "Survived [1] steps\nTotal reward [1081.1182861328125]\nSurvived [1] steps\nTotal reward [1083.3673095703125]\n",
      "Survived [2] steps\nTotal reward [2186.1871337890625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps\nTotal reward [2133.7645263671875]\n",
      "Survived [2] steps\nTotal reward [2211.42431640625]\n",
      "Survived [5] steps\nTotal reward [5541.4644775390625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps",
      "\nTotal reward [2161.79638671875]\nSurvived [1] steps\nTotal reward [1063.3914794921875]\n",
      "Survived [6] steps\nTotal reward [6592.4615478515625]\n",
      "Survived [3] steps\nTotal reward [3216.212890625]\n",
      "Survived [3] steps\nTotal reward [3312.7425537109375]\n",
      "Survived [4] steps\nTotal reward [4548.7265625]\nSurvived [1] steps\nTotal reward [1055.8333740234375]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [1] steps\nTotal reward [1117.864013671875]\n",
      "Survived [2] steps\nTotal reward [2109.544677734375]\n",
      "Survived [4] steps\nTotal reward [4450.5748291015625]\n",
      "Survived [6] steps\nTotal reward [6644.855712890625]\nSurvived [1] steps\nTotal reward [1088.509765625]\n",
      "Survived [1] steps\nTotal reward [1106.888427734375]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps\nTotal reward [2187.6304931640625]\n",
      "Survived [1] steps\nTotal reward [1044.0428466796875]\nSurvived [2] steps",
      "\nTotal reward [2197.5703125]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [1] steps\nTotal reward [1114.8758544921875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2158.9560546875]\nSurvived [1] steps\nTotal reward [1082.4085693359375]\n",
      "Survived [1] steps\nTotal reward [1099.5338134765625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps\nTotal reward [2161.4305419921875]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [1] steps\nTotal reward [1066.4609375]\n",
      "Survived [3] steps\nTotal reward [3178.96142578125]\nSurvived [2] steps",
      "\nTotal reward [2266.220947265625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [1] steps\nTotal reward [1088.8848876953125]\n",
      "Survived [4] steps\nTotal reward [4401.434814453125]\n",
      "Survived [3] steps\nTotal reward [3151.4429931640625]\nSurvived [2] steps\nTotal reward [2161.421875]\n",
      "Survived [3] steps\nTotal reward [3193.21142578125]\nSurvived [3] steps",
      "\nTotal reward [3228.7039794921875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2192.8232421875]\nSurvived [2] steps",
      "\nTotal reward [2193.8026123046875]\nSurvived [1] steps\nTotal reward [1067.2568359375]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [1] steps\nTotal reward [1152.7078857421875]\n",
      "Survived [1] steps\nTotal reward [1088.201904296875]\nSurvived [3] steps",
      "\nTotal reward [3235.192626953125]\nSurvived [2] steps",
      "\nTotal reward [2193.3968505859375]\nSurvived [2] steps\nTotal reward [2123.9718017578125]\n",
      "Survived [2] steps\nTotal reward [2126.67822265625]\n",
      "Survived [2] steps\nTotal reward [2161.304931640625]\n",
      "Successfully saved model at: saved_agent_DDDQN_10\\test_agent.h5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from grid2op import make\n",
    "from grid2op.Agent import RandomAgent \n",
    "max_iter = 50 # to make computation much faster we will only consider 50 time steps instead of 287\n",
    "train_iter = 10\n",
    "env_name = \"rte_case14_realistic\"\n",
    "# create an environment\n",
    "env = make(env_name)  \n",
    "# don't forget to set \"test=False\" (or remove it, as False is the default value) for \"real\" training\n",
    "\n",
    "# import the train function and train your agent\n",
    "from l2rpn_baselines.DoubleDuelingDQN import train\n",
    "agent_name = \"test_agent\"\n",
    "save_path = \"saved_agent_DDDQN_{}\".format(train_iter)\n",
    "train(env,\n",
    "      name=agent_name,\n",
    "      iterations=train_iter,\n",
    "      save_path=save_path,\n",
    "      load_path=None, # put something else if you want to reload an agent instead of creating a new one\n",
    "      logs_path=\"tf_logs_DDDQN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}