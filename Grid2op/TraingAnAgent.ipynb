{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Step [0] -- Random [0.99]\nSurvived [2] steps\nTotal reward [2177.73388671875]\n",
      "Survived [4] steps\nTotal reward [4358.49462890625]\n",
      "Survived [3] steps\nTotal reward [3323.398193359375]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [6] steps\nTotal reward [6546.0113525390625]\n",
      "Survived [5] steps\nTotal reward [5523.74267578125]\n",
      "Survived [3] steps\nTotal reward [3217.681640625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [4] steps\nTotal reward [4477.2669677734375]\nSurvived [2] steps",
      "\nTotal reward [2258.4945068359375]\nSurvived [2] steps",
      "\nTotal reward [2211.9261474609375]\n",
      "Survived [5] steps\nTotal reward [5648.634033203125]\nSurvived [2] steps",
      "\nTotal reward [2175.1243896484375]\nSurvived [2] steps",
      "\nTotal reward [2243.9976806640625]\nSurvived [3] steps",
      "\nTotal reward [3201.152587890625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [3] steps\nTotal reward [3298.3116455078125]\nSurvived [1] steps\nTotal reward [1093.921875]\n",
      "Survived [1] steps\nTotal reward [1112.0511474609375]\n",
      "Survived [4] steps\nTotal reward [4319.05029296875]\nSurvived [1] steps\nTotal reward [1130.4378662109375]\n",
      "Survived [4] steps\nTotal reward [4402.7581787109375]\nSurvived [2] steps\nTotal reward [2245.8377685546875]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [1] steps\nTotal reward [1090.440185546875]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2085.0078125]\n",
      "Survived [4] steps\nTotal reward [4306.07470703125]\nSurvived [2] steps",
      "\nTotal reward [2220.284912109375]\n",
      "Survived [3] steps\nTotal reward [3346.56005859375]\nSurvived [4] steps",
      "\nTotal reward [4377.8876953125]\nSurvived [1] steps\nTotal reward [1083.672119140625]\n",
      "Survived [1] steps\nTotal reward [1083.035400390625]\n",
      "Survived [4] steps\nTotal reward [4417.16845703125]\nSurvived [2] steps",
      "\nTotal reward [2149.39892578125]\nSurvived [1] steps\nTotal reward [1099.3277587890625]\n",
      "Survived [3] steps\nTotal reward [3212.6827392578125]\n",
      "Survived [1] steps\nTotal reward [1091.40185546875]\n",
      "Survived [4] steps\nTotal reward [4478.739013671875]\n",
      "Survived [0] steps\nTotal reward [-10.0]\n",
      "Survived [4] steps\nTotal reward [4412.75244140625]\n",
      "Survived [4] steps\nTotal reward [4389.097900390625]\nSurvived [1] steps",
      "\nTotal reward [1079.4874267578125]\n",
      "Survived [2] steps\nTotal reward [2155.01708984375]\n",
      "Survived [2] steps\nTotal reward [2140.1470947265625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2162.8671875]\n",
      "Survived [2] steps\nTotal reward [2209.2626953125]\n",
      "Survived [2] steps\nTotal reward [2262.4158935546875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2163.650146484375]\n",
      "Survived [4] steps\nTotal reward [4423.6478271484375]\nSurvived [1] steps\nTotal reward [1073.2584228515625]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps\nTotal reward [2197.51513671875]\n",
      "Survived [3] steps\nTotal reward [3264.9053955078125]\nSurvived [1] steps\nTotal reward [1107.535400390625]\n",
      "Survived [2] steps\nTotal reward [2220.995849609375]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [3] steps\nTotal reward [3321.3489990234375]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [2] steps",
      "\nTotal reward [2153.3861083984375]\nSurvived [2] steps\nTotal reward [2198.4200439453125]\n",
      "Survived [5] steps\nTotal reward [5439.7294921875]\nSurvived [2] steps",
      "\nTotal reward [2170.1763916015625]\n",
      "Survived [4] steps\nTotal reward [4353.915283203125]\n",
      "Survived [3] steps\nTotal reward [3326.321044921875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [0] steps\nTotal reward [-10.0]\nSurvived [1] steps\nTotal reward [1074.3756103515625]\n",
      "Survived [3] steps\nTotal reward [3358.5162353515625]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2147.56396484375]\nSurvived [2] steps",
      "\nTotal reward [2270.3494873046875]\n",
      "Survived [3] steps\nTotal reward [3295.7255859375]\nSurvived [3] steps",
      "\nTotal reward [3291.9093017578125]\n",
      "Survived [3] steps\nTotal reward [3292.139404296875]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [3] steps\nTotal reward [3185.8824462890625]\nSurvived [2] steps",
      "\nTotal reward [2142.1055908203125]\nSurvived [2] steps",
      "\nTotal reward [2149.7568359375]\nSurvived [0] steps\nTotal reward [-10.0]\n",
      "Survived [2] steps\nTotal reward [2220.902099609375]\nSurvived [1] steps\nTotal reward [1108.0263671875]\n",
      "Survived [4] steps\nTotal reward [4286.5184326171875]\nSuccessfully saved model at: saved_agent_DDDQN_10\\test_agent.h5",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from grid2op import make\n",
    "from grid2op.Agent import RandomAgent \n",
    "max_iter = 10 # to make computation much faster we will only consider 50 time steps instead of 287\n",
    "train_iter = 10\n",
    "env_name = \"rte_case14_realistic\"\n",
    "# create an environment\n",
    "env = make(env_name)  \n",
    "# don't forget to set \"test=False\" (or remove it, as False is the default value) for \"real\" training\n",
    "\n",
    "# import the train function and train your agent\n",
    "from l2rpn_baselines.DoubleDuelingDQN import train\n",
    "agent_name = \"test_agent\"\n",
    "save_path = \"saved_agent_DDDQN_{}\".format(train_iter)\n",
    "train(env,\n",
    "      name=agent_name,\n",
    "      iterations=train_iter,\n",
    "      save_path=save_path,\n",
    "      load_path=None, # put something else if you want to reload an agent instead of creating a new one\n",
    "      logs_path=\"tf_logs_DDDQN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}